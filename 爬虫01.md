# 爬虫学习

## 2.1 关于爬虫的合法性

注：每个网站都有一个名为 robots.txt的文档

## 2.3 使用requests库请求网站

### 2.3.1 安装requests库

### 2.3.2爬虫的基本原理

（1）网页请求的过程

- Request(请求)
- Response(响应)

（2）网页请求的方式

GET：最常见的方式，一般用于获取或者查询资源信息，也是大多数网站使用的方式，响应速度快。

POST：相比GET方式，多了以表单形式上传参数的功能，因此除查询信息外，还可以修改信息。

### 2.3.3 使用GET方式抓取数据

在任意网页使用组合键【ctrl+u】调出网页源码，再使用组合键【ctrl+F】调出搜索框，再点击ENTER键

**注：所有在源码中的数据请求方式都是GET**

```python
#请求例子
import requests
url = 'http://www.cntour.cn/'
strhtml = requests.get(url)
print(strhtml.text)
```

### 2.3.4 使用POST方式抓取数据

下面使用的是例子是有道翻译的网站：http://fanyi.youdao.com/

按快捷键F12进入开发者模式，单击网络找到输入的数据

![Spider01](https://github.com/123YoLo/Python_study/blob/main/Spider01.png)

找到后明确请求方式是POST

![Spider02](https://github.com/123YoLo/Python_study/blob/main/Spider02.png)

表单数据在这里！！！！！

![Spider03](https://github.com/123YoLo/Python_study/blob/main/Spider03.png)

```python
#抓取有道翻译结果的完整
import requests
import json
def get_translate_data(word=None):
    url = 'https://fanyi.youdao.com/translate_o?smartresult=dict&smartresult=rule'
    Form_data={'i':'我爱中国','from':'AUTO','to':'AUTO','smartresult':'dict','client':'fanyideskweb',
           'salt':'16384230005986','sign':'1189d3a64f30b09a07833db0eca9751c','its':'1638423000598'
           ,'bv':'33e494f528b222a258ab981c1e02e301','doctype':'json','version':'2.1','keyfrom':'fanyi.web'
            ,'action':'FY_BY_REALTlME'
           }
    #请求表单数据
    reponse = requests.post(url,data = Form_data)
    #讲JSON格式字符串转为字典
    content = json.loads(reponse.text)
    #打印翻译后的数据
    print(content['translateResult'][0][0]['tgt'])
    if __name__ == '__main__':
     get_translate_data('我爱数据')
```

